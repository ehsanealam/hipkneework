{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sjwWpLJuRrr63qWHrfhjhlUJKn6efyTn",
      "authorship_tag": "ABX9TyMHONPxgZL5N30cQ3fFVb2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehsanealam/hipkneework/blob/main/hipkneeacp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydicom\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4EpLe6enZo6",
        "outputId": "fd2ab7bf-6987-48ff-d820-82f0ae845878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nibabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6LtOEzFnbvq",
        "outputId": "58d6a544-4f48-443f-baf2-22b033a904df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.23.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Set paths to dataset folders and files\n",
        "hip_images_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "hip_annotations_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "hip_csv_file = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/segmentation.csv\"\n",
        "\n",
        "# Load CSV metadata\n",
        "metadata = pd.read_csv(hip_csv_file)\n",
        "\n",
        "# Function to load DICOM images\n",
        "def load_dicom_images(folder_path):\n",
        "    image_data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".dcm\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            dicom_data = pydicom.dcmread(filepath)\n",
        "            image_data.append(dicom_data.pixel_array)\n",
        "    return np.array(image_data)\n",
        "\n",
        "# Function to load NIfTI annotations and resize them to a common shape\n",
        "def load_and_resize_nifti_annotations(file_path, target_shape):\n",
        "    nifti_data = nib.load(file_path)\n",
        "    annotations = nifti_data.get_fdata()\n",
        "    annotations_resized = resize(annotations, target_shape, anti_aliasing=True)\n",
        "    return annotations_resized\n",
        "\n",
        "# Function to filter and load DICOM images based on metadata\n",
        "def image_data_generator(folder_path, metadata, attribute_name, attribute_value, num_samples, target_shape, batch_size=32):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_annotations = []\n",
        "        samples_loaded = 0\n",
        "        for index, row in metadata.iterrows():\n",
        "            if row[attribute_name] == attribute_value and samples_loaded < num_samples:\n",
        "                image_id = row['id']\n",
        "                filename = f\"{image_id}.dcm\"\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                dicom_data = pydicom.dcmread(filepath)\n",
        "                image = dicom_data.pixel_array\n",
        "                annotation_filename = f\"{image_id}.nii.gz\"\n",
        "                annotation_filepath = os.path.join(hip_annotations_folder, annotation_filename)\n",
        "                annotation_data = load_and_resize_nifti_annotations(annotation_filepath, target_shape)\n",
        "                batch_images.append(image)\n",
        "                batch_annotations.append(annotation_data)\n",
        "                samples_loaded += 1\n",
        "        yield ([np.array(batch_images), np.array(batch_annotations)], np.array(batch_annotations))\n",
        "\n",
        "\n",
        "num_samples = 200  # Number of samples to load for each subset\n",
        "target_shape = (256, 256, 1)  # Target shape for images and annotations\n",
        "\n",
        "male_gender = '1: Male'  # Specify the gender to filter\n",
        "male_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', male_gender, num_samples, target_shape)\n",
        "\n",
        "female_gender = '2: Female'  # Specify the gender to filter\n",
        "female_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', female_gender, num_samples, target_shape)\n",
        "\n",
        "# Split the dataset into train and test sets for male and female subsets\n",
        "male_data = list(male_data_generator)\n",
        "female_data = list(female_data_generator)\n",
        "\n",
        "male_X, male_y = zip(*male_data)\n",
        "female_X, female_y = zip(*female_data)\n",
        "\n",
        "male_X_train, male_X_test, male_y_train, male_y_test = train_test_split(male_X, male_y, test_size=0.2, random_state=42)\n",
        "female_X_train, female_X_test, female_y_train, female_y_test = train_test_split(female_X, female_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an ImageDataGenerator with data augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,  # Randomly shift image width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift image height by up to 10%\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Randomly zoom in on images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest neighbor strategy\n",
        ")\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for male and female subsets\n",
        "male_data_generator = datagen.flow(np.array(male_X_train), np.array(male_y_train), batch_size=batch_size, shuffle=True)\n",
        "female_data_generator = datagen.flow(np.array(female_X_train), np.array(female_y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the U-Net model architecture\n",
        "def unet_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    # Decoder\n",
        "    up1 = UpSampling2D(size=(2, 2))(pool2)\n",
        "    conv3 = Conv2D(64, 3, activation='relu', padding='same')(up1)\n",
        "    conv4 = Conv2D(1, 1, activation='sigmoid')(conv3)\n",
        "    return Model(inputs, conv4)\n",
        "\n",
        "# Compile and train the male model\n",
        "male_model = unet_model(input_shape=(256, 256, 1))\n",
        "male_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "male_model.fit(male_data_generator, epochs=10, steps_per_epoch=len(male_X_train) // batch_size, validation_split=0.1)\n",
        "# Compile and train the female model\n",
        "female_model = unet_model(input_shape=(256, 256, 1))\n",
        "female_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "female_model.fit(female_data_generator, epochs=10, steps_per_epoch=len(female_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the male model on the test set\n",
        "male_test_loss, male_test_accuracy = male_model.evaluate(np.array(male_X_test), np.array(male_y_test))\n",
        "print(f'Male Test Loss: {male_test_loss}, Male Test Accuracy: {male_test_accuracy}')\n",
        "\n",
        "# Evaluate the female model on the test set\n",
        "female_test_loss, female_test_accuracy = female_model.evaluate(np.array(female_X_test), np.array(female_y_test))\n",
        "print(f'Female Test Loss: {female_test_loss}, Female Test Accuracy: {female_test_accuracy}')\n",
        "\n",
        "# Calculate IoU for male and female models on the test set\n",
        "male_y_pred = male_model.predict(np.array(male_X_test))\n",
        "female_y_pred = female_model.predict(np.array(female_X_test))\n",
        "\n",
        "male_iou = calculate_iou(np.array(male_y_test), male_y_pred)\n",
        "female_iou = calculate_iou(np.array(female_y_test), female_y_pred)\n",
        "\n",
        "print(f'Male IoU: {male_iou}')\n",
        "print(f'Female IoU: {female_iou}')\n",
        "\n"
      ],
      "metadata": {
        "id": "yfENIRScnSjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lycY8gnInOvf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Set paths to dataset folders and files\n",
        "hip_images_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "hip_annotations_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "hip_csv_file = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/segmentation.csv\"\n",
        "\n",
        "# Load CSV metadata\n",
        "metadata = pd.read_csv(hip_csv_file)\n",
        "\n",
        "# Function to load DICOM images\n",
        "def load_dicom_images(folder_path):\n",
        "    image_data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".dcm\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            dicom_data = pydicom.dcmread(filepath)\n",
        "            image_data.append(dicom_data.pixel_array)\n",
        "    return np.array(image_data)\n",
        "\n",
        "# Function to load NIfTI annotations and resize them to a common shape\n",
        "def load_and_resize_nifti_annotations(file_path, target_shape):\n",
        "    nifti_data = nib.load(file_path)\n",
        "    annotations = nifti_data.get_fdata()\n",
        "    annotations_resized = resize(annotations, target_shape, anti_aliasing=True)\n",
        "    return annotations_resized\n",
        "\n",
        "# Function to filter and load DICOM images based on metadata\n",
        "def image_data_generator(folder_path, metadata, attribute_name, attribute_value, num_samples, target_shape, batch_size=32):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_annotations = []\n",
        "        samples_loaded = 0\n",
        "        for index, row in metadata.iterrows():\n",
        "            if row[attribute_name] == attribute_value and samples_loaded < num_samples:\n",
        "                image_id = row['id']\n",
        "                filename = f\"{image_id}.dcm\"\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                dicom_data = pydicom.dcmread(filepath)\n",
        "                image = dicom_data.pixel_array\n",
        "                annotation_filename = f\"{image_id}.nii.gz\"\n",
        "                annotation_filepath = os.path.join(hip_annotations_folder, annotation_filename)\n",
        "                annotation_data = load_and_resize_nifti_annotations(annotation_filepath, target_shape)\n",
        "                batch_images.append(image)\n",
        "                batch_annotations.append(annotation_data)\n",
        "                samples_loaded += 1\n",
        "        yield ([np.array(batch_images), np.array(batch_annotations)], np.array(batch_annotations))\n",
        "\n",
        "\n",
        "num_samples = 200  # Number of samples to load for each subset\n",
        "target_shape = (256, 256, 1)  # Target shape for images and annotations\n",
        "\n",
        "male_gender = '1: Male'  # Specify the gender to filter\n",
        "male_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', male_gender, num_samples, target_shape)\n",
        "\n",
        "female_gender = '2: Female'  # Specify the gender to filter\n",
        "female_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', female_gender, num_samples, target_shape)\n",
        "\n",
        "# Split the dataset into train and test sets for male and female subsets\n",
        "male_data = list(male_data_generator)\n",
        "female_data = list(female_data_generator)\n",
        "\n",
        "male_X, male_y = zip(*male_data)\n",
        "female_X, female_y = zip(*female_data)\n",
        "\n",
        "male_X_train, male_X_test, male_y_train, male_y_test = train_test_split(male_X, male_y, test_size=0.2, random_state=42)\n",
        "female_X_train, female_X_test, female_y_train, female_y_test = train_test_split(female_X, female_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an ImageDataGenerator with data augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,  # Randomly shift image width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift image height by up to 10%\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Randomly zoom in on images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest neighbor strategy\n",
        ")\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for male and female subsets\n",
        "male_data_generator = datagen.flow(np.array(male_X_train), np.array(male_y_train), batch_size=batch_size, shuffle=True)\n",
        "female_data_generator = datagen.flow(np.array(female_X_train), np.array(female_y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the U-Net model architecture with ResNet-50 backbone\n",
        "def unet_resnet50_model(input_shape):\n",
        "    # Encoder (ResNet-50)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False  # Freeze the weights of the ResNet-50 layers\n",
        "\n",
        "    # Decoder\n",
        "    inputs = Input(input_shape)\n",
        "    skip_connections = list()\n",
        "\n",
        "    x = base_model(inputs)\n",
        "    skip_connections.append(x)\n",
        "\n",
        "    for i in range(len(base_model.layers) - 1, -1, -1):\n",
        "        if isinstance(base_model.layers[i], tf.keras.layers.MaxPooling2D):\n",
        "            break\n",
        "        x = base_model.layers[i](x)\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = Concatenate(axis=3)([x, skip_connections[-1]])\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Compile and train the male model with ResNet-50 backbone\n",
        "male_model = unet_resnet50_model(input_shape=(256, 256, 3))\n",
        "male_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "male_model.fit(male_data_generator, epochs=10, steps_per_epoch=len(male_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Compile and train the female model with ResNet-50 backbone\n",
        "female_model = unet_resnet50_model(input_shape=(256, 256, 3))\n",
        "female_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "female_model.fit(female_data_generator, epochs=10, steps_per_epoch=len(female_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the male model on the test set\n",
        "male_test_loss, male_test_accuracy = male_model.evaluate(np.array(male_X_test), np.array(male_y_test))\n",
        "print(f'Male Test Loss: {male_test_loss}, Male Test Accuracy: {male_test_accuracy}')\n",
        "\n",
        "# Evaluate the female model on the test set\n",
        "female_test_loss, female_test_accuracy = female_model.evaluate(np.array(female_X_test), np.array(female_y_test))\n",
        "print(f'Female Test Loss: {female_test_loss}, Female Test Accuracy: {female_test_accuracy}')\n",
        "\n",
        "# Calculate IoU for male and female models on the test set\n",
        "male_y_pred = male_model.predict(np.array(male_X_test))\n",
        "female_y_pred = female_model.predict(np.array(female_X_test))\n",
        "\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "male_iou = calculate_iou(np.array(male_y_test), male_y_pred)\n",
        "female_iou = calculate_iou(np.array(female_y_test), female_y_pred)\n",
        "\n",
        "print(f'Male IoU: {male_iou}')\n",
        "print(f'Female IoU: {female_iou}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "# Set paths to dataset folders and files\n",
        "hip_images_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "hip_annotations_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "hip_csv_file = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/segmentation.csv\"\n",
        "\n",
        "# Load CSV metadata\n",
        "metadata = pd.read_csv(hip_csv_file)\n",
        "\n",
        "# Function to load DICOM images\n",
        "def load_dicom_images(folder_path):\n",
        "    image_data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".dcm\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            dicom_data = pydicom.dcmread(filepath)\n",
        "            image_data.append(dicom_data.pixel_array)\n",
        "    return np.array(image_data)\n",
        "\n",
        "# Function to load NIfTI annotations and resize them to a common shape\n",
        "def load_and_resize_nifti_annotations(file_path, target_shape):\n",
        "    nifti_data = nib.load(file_path)\n",
        "    annotations = nifti_data.get_fdata()\n",
        "    annotations_resized = resize(annotations, target_shape, anti_aliasing=True)\n",
        "    return annotations_resized\n",
        "\n",
        "# Function to filter and load DICOM images based on metadata\n",
        "def image_data_generator(folder_path, metadata, attribute_name, attribute_value, num_samples, target_shape, batch_size=32):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_annotations = []\n",
        "        samples_loaded = 0\n",
        "        for index, row in metadata.iterrows():\n",
        "            if row[attribute_name] == attribute_value and samples_loaded < num_samples:\n",
        "                image_id = row['id']\n",
        "                filename = f\"{image_id}.dcm\"\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                dicom_data = pydicom.dcmread(filepath)\n",
        "                image = dicom_data.pixel_array\n",
        "                annotation_filename = f\"{image_id}.nii.gz\"\n",
        "                annotation_filepath = os.path.join(hip_annotations_folder, annotation_filename)\n",
        "                annotation_data = load_and_resize_nifti_annotations(annotation_filepath, target_shape)\n",
        "                batch_images.append(image)\n",
        "                batch_annotations.append(annotation_data)\n",
        "                samples_loaded += 1\n",
        "        yield ([np.array(batch_images), np.array(batch_annotations)], np.array(batch_annotations))\n",
        "\n",
        "\n",
        "num_samples = 200  # Number of samples to load for each subset\n",
        "target_shape = (256, 256, 1)  # Target shape for images and annotations\n",
        "\n",
        "male_gender = '1: Male'  # Specify the gender to filter\n",
        "male_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', male_gender, num_samples, target_shape)\n",
        "\n",
        "female_gender = '2: Female'  # Specify the gender to filter\n",
        "female_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', female_gender, num_samples, target_shape)\n",
        "\n",
        "# Split the dataset into train and test sets for male and female subsets\n",
        "male_data = list(male_data_generator)\n",
        "female_data = list(female_data_generator)\n",
        "\n",
        "male_X, male_y = zip(*male_data)\n",
        "female_X, female_y = zip(*female_data)\n",
        "\n",
        "male_X_train, male_X_test, male_y_train, male_y_test = train_test_split(male_X, male_y, test_size=0.2, random_state=42)\n",
        "female_X_train, female_X_test, female_y_train, female_y_test = train_test_split(female_X, female_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an ImageDataGenerator with data augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,  # Randomly shift image width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift image height by up to 10%\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Randomly zoom in on images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest neighbor strategy\n",
        ")\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for male and female subsets\n",
        "male_data_generator = datagen.flow(np.array(male_X_train), np.array(male_y_train), batch_size=batch_size, shuffle=True)\n",
        "female_data_generator = datagen.flow(np.array(female_X_train), np.array(female_y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the U-Net model architecture with DenseNet-121 backbone\n",
        "def unet_densenet121_model(input_shape):\n",
        "    # Encoder (DenseNet-121)\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False  # Freeze the weights of the DenseNet-121 layers\n",
        "\n",
        "    # Decoder\n",
        "    inputs = Input(input_shape)\n",
        "    skip_connections = list()\n",
        "\n",
        "    x = base_model(inputs)\n",
        "    skip_connections.append(x)\n",
        "\n",
        "    for i in range(len(base_model.layers) - 1, -1, -1):\n",
        "        if isinstance(base_model.layers[i], tf.keras.layers.MaxPooling2D):\n",
        "            break\n",
        "        x = base_model.layers[i](x)\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = Concatenate(axis=3)([x, skip_connections[-1]])\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Compile and train the male model with DenseNet-121 backbone\n",
        "male_model = unet_densenet121_model(input_shape=(256, 256, 3))\n",
        "male_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "male_model.fit(male_data_generator, epochs=10, steps_per_epoch=len(male_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Compile and train the female model with DenseNet-121 backbone\n",
        "female_model = unet_densenet121_model(input_shape=(256, 256, 3))\n",
        "female_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "female_model.fit(female_data_generator, epochs=10, steps_per_epoch=len(female_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the male model on the test set\n",
        "male_test_loss, male_test_accuracy = male_model.evaluate(np.array(male_X_test), np.array(male_y_test))\n",
        "print(f'Male Test Loss: {male_test_loss}, Male Test Accuracy: {male_test_accuracy}')\n",
        "\n",
        "# Evaluate the female model on the test set\n",
        "female_test_loss, female_test_accuracy = female_model.evaluate(np.array(female_X_test), np.array(female_y_test))\n",
        "print(f'Female Test Loss: {female_test_loss}, Female Test Accuracy: {female_test_accuracy}')\n",
        "\n",
        "# Calculate IoU for male and female models on the test set\n",
        "male_y_pred = male_model.predict(np.array(male_X_test))\n",
        "female_y_pred = female_model.predict(np.array(female_X_test))\n",
        "\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "male_iou = calculate_iou(np.array(male_y_test), male_y_pred)\n",
        "female_iou = calculate_iou(np.array(female_y_test), female_y_pred)\n",
        "\n",
        "print(f'Male IoU: {male_iou}')\n",
        "print(f'Female IoU: {female_iou}')\n"
      ],
      "metadata": {
        "id": "v8018PD-ndy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# Set paths to dataset folders and files\n",
        "hip_images_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Images\"\n",
        "hip_annotations_folder = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/Annotations\"\n",
        "hip_csv_file = \"dataset/JHIR_Hip_Knee_Datasets/JHIR_Hip_Knee_Datasets/Hip/segmentation.csv\"\n",
        "\n",
        "# Load CSV metadata\n",
        "metadata = pd.read_csv(hip_csv_file)\n",
        "\n",
        "# Function to load DICOM images\n",
        "def load_dicom_images(folder_path):\n",
        "    image_data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".dcm\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            dicom_data = pydicom.dcmread(filepath)\n",
        "            image_data.append(dicom_data.pixel_array)\n",
        "    return np.array(image_data)\n",
        "\n",
        "# Function to load NIfTI annotations and resize them to a common shape\n",
        "def load_and_resize_nifti_annotations(file_path, target_shape):\n",
        "    nifti_data = nib.load(file_path)\n",
        "    annotations = nifti_data.get_fdata()\n",
        "    annotations_resized = resize(annotations, target_shape, anti_aliasing=True)\n",
        "    return annotations_resized\n",
        "\n",
        "# Function to filter and load DICOM images based on metadata\n",
        "def image_data_generator(folder_path, metadata, attribute_name, attribute_value, num_samples, target_shape, batch_size=32):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_annotations = []\n",
        "        samples_loaded = 0\n",
        "        for index, row in metadata.iterrows():\n",
        "            if row[attribute_name] == attribute_value and samples_loaded < num_samples:\n",
        "                image_id = row['id']\n",
        "                filename = f\"{image_id}.dcm\"\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                dicom_data = pydicom.dcmread(filepath)\n",
        "                image = dicom_data.pixel_array\n",
        "                annotation_filename = f\"{image_id}.nii.gz\"\n",
        "                annotation_filepath = os.path.join(hip_annotations_folder, annotation_filename)\n",
        "                annotation_data = load_and_resize_nifti_annotations(annotation_filepath, target_shape)\n",
        "                batch_images.append(image)\n",
        "                batch_annotations.append(annotation_data)\n",
        "                samples_loaded += 1\n",
        "        yield ([np.array(batch_images), np.array(batch_annotations)], np.array(batch_annotations))\n",
        "\n",
        "# Load images and annotations for a specific subset of data (e.g., based on gender)\n",
        "num_samples = 200  # Number of samples to load for each subset\n",
        "target_shape = (256, 256, 1)  # Target shape for images and annotations\n",
        "\n",
        "male_gender = '1: Male'  # Specify the gender to filter\n",
        "male_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', male_gender, num_samples, target_shape)\n",
        "\n",
        "female_gender = '2: Female'  # Specify the gender to filter\n",
        "female_data_generator = image_data_generator(hip_images_folder, metadata, 'P02SEX', female_gender, num_samples, target_shape)\n",
        "\n",
        "# Split the dataset into train and test sets for male and female subsets\n",
        "male_data = list(male_data_generator)\n",
        "female_data = list(female_data_generator)\n",
        "\n",
        "male_X, male_y = zip(*male_data)\n",
        "female_X, female_y = zip(*female_data)\n",
        "\n",
        "male_X_train, male_X_test, male_y_train, male_y_test = train_test_split(male_X, male_y, test_size=0.2, random_state=42)\n",
        "female_X_train, female_X_test, female_y_train, female_y_test = train_test_split(female_X, female_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an ImageDataGenerator with data augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,  # Randomly shift image width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift image height by up to 10%\n",
        "    shear_range=0.2,  # Shear intensity\n",
        "    zoom_range=0.2,  # Randomly zoom in on images\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest neighbor strategy\n",
        ")\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for male and female subsets\n",
        "male_data_generator = datagen.flow(np.array(male_X_train), np.array(male_y_train), batch_size=batch_size, shuffle=True)\n",
        "female_data_generator = datagen.flow(np.array(female_X_train), np.array(female_y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the U-Net model architecture with EfficientNet-B0 backbone\n",
        "def unet_efficientnetb0_model(input_shape):\n",
        "    # Encoder (EfficientNet-B0)\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False  # Freeze the weights of the EfficientNet-B0 layers\n",
        "\n",
        "    # Decoder\n",
        "    inputs = Input(input_shape)\n",
        "    skip_connections = list()\n",
        "\n",
        "    x = base_model(inputs)\n",
        "    skip_connections.append(x)\n",
        "\n",
        "    for i in range(len(base_model.layers) - 1, -1, -1):\n",
        "        if isinstance(base_model.layers[i], tf.keras.layers.MaxPooling2D):\n",
        "            break\n",
        "        x = base_model.layers[i](x)\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = Concatenate(axis=3)([x, skip_connections[-1]])\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Compile and train the male model with EfficientNet-B0 backbone\n",
        "male_model = unet_efficientnetb0_model(input_shape=(256, 256, 3))\n",
        "male_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "male_model.fit(male_data_generator, epochs=10, steps_per_epoch=len(male_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Compile and train the female model with EfficientNet-B0 backbone\n",
        "female_model = unet_efficientnetb0_model(input_shape=(256, 256, 3))\n",
        "female_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model using the data generator\n",
        "female_model.fit(female_data_generator, epochs=10, steps_per_epoch=len(female_X_train) // batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the male model on the test set\n",
        "male_test_loss, male_test_accuracy = male_model.evaluate(np.array(male_X_test), np.array(male_y_test))\n",
        "print(f'Male Test Loss: {male_test_loss}, Male Test Accuracy: {male_test_accuracy}')\n",
        "\n",
        "# Evaluate the female model on the test set\n",
        "female_test_loss, female_test_accuracy = female_model.evaluate(np.array(female_X_test), np.array(female_y_test))\n",
        "print(f'Female Test Loss: {female_test_loss}, Female Test Accuracy: {female_test_accuracy}')\n",
        "\n",
        "# Calculate IoU for male and female models on the test set\n",
        "male_y_pred = male_model.predict(np.array(male_X_test))\n",
        "female_y_pred = female_model.predict(np.array(female_X_test))\n",
        "\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "male_iou = calculate_iou(np.array(male_y_test), male_y_pred)\n",
        "female_iou = calculate_iou(np.array(female_y_test), female_y_pred)\n",
        "\n",
        "print(f'Male IoU: {male_iou}')\n",
        "print(f'Female IoU: {female_iou}')\n"
      ],
      "metadata": {
        "id": "eQLlsDWgoUhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}